{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (r'..\\data\\data_ready.csv')\n",
    "traffic_path = (r'..\\data\\traffic_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path,index_col=0)\n",
    "traffic = pd.read_excel(traffic_path, engine='openpyxl', sheet_name='udaljenosti', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funkcije za normalzaciju traffica-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_norm(x):\n",
    "    df=traffic.drop(x,axis=0)\n",
    "    df=df[[x]]\n",
    "    df['norm']=df[[x]]/df[[x]].max()\n",
    "    df=df.drop(x,axis=1)\n",
    "    df = df.filter(like='_80',axis=0)\n",
    "    df=df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_s_norm(data,y):\n",
    "    x = data.copy()\n",
    "    x1 = x.filter(like='_80',axis=1)\n",
    "    x1 = x1.sort_index(axis=1)\n",
    "    for i,j in zip(x1.columns,y.norm):\n",
    "        x1[i]=x1[i]*j\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funckcija za podatke "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sites(site_1,pollutant_1):\n",
    "    df = data.copy()\n",
    "    df2 = df[[pollutant_1]]\n",
    "    df1 = df.filter(like=site_1, axis=1)\n",
    "    df3 = df[['Cloud_Cover_Mean','Temperature_Air_2m_Max_Day_Time', 'Temperature_Air_2m_Min_Night_Time','Wind_Speed_10m_Mean']]\n",
    "    df4 = df[['year', 'dayofyear', 'month_Apr', 'month_Aug', 'month_Dec',\n",
    "       'month_Feb', 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar',\n",
    "       'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'weekday_Friday',\n",
    "       'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday',\n",
    "       'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday',\n",
    "       'season_fall', 'season_spring', 'season_summer', 'season_winter', 'holiday', 'holiday_school']]\n",
    "    d = pd.concat([df1,df2,df3,df4],axis=1)\n",
    "    X = d.drop(pollutant_1,axis=1)\n",
    "    Y = d[[pollutant_1]] \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funkcija bez traffica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sites_bez_traffic(site_1,pollutant_1):\n",
    "    df = data.copy()\n",
    "    df2 = df[[pollutant_1]]\n",
    "    df1 = df.filter(like=site_1, axis=1)\n",
    "    df3 = df[['Cloud_Cover_Mean','Temperature_Air_2m_Max_Day_Time', 'Temperature_Air_2m_Min_Night_Time','Wind_Speed_10m_Mean']]\n",
    "    df4 = df[['year', 'dayofyear', 'month_Apr', 'month_Aug', 'month_Dec',\n",
    "       'month_Feb', 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar',\n",
    "       'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'weekday_Friday',\n",
    "       'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday',\n",
    "       'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday',\n",
    "       'season_fall', 'season_spring', 'season_summer', 'season_winter', 'holiday', 'holiday_school']]\n",
    "    d = pd.concat([df1,df2,df3,df4],axis=1)\n",
    "    df5 = d.filter(like='_80', axis=1)\n",
    "    \n",
    "    X = d.drop(df5.columns,axis=1)\n",
    "    X = d.drop(pollutant_1,axis=1)\n",
    "    Y = d[[pollutant_1]] \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funkcija za norm traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sites_s_norm_traffic(site_1,pollutant_1,traffic_1):\n",
    "    df = data.copy()\n",
    "    df_t = traffic_1.copy()\n",
    "    df_t = df_t.filter(like=site_1,axis=1)\n",
    "    df2 = df[[pollutant_1]]\n",
    "    df1 = df.filter(like=site_1, axis=1)\n",
    "    df3 = df[['Cloud_Cover_Mean','Temperature_Air_2m_Max_Day_Time', 'Temperature_Air_2m_Min_Night_Time','Wind_Speed_10m_Mean']]\n",
    "    df4 = df[['year', 'dayofyear', 'month_Apr', 'month_Aug', 'month_Dec',\n",
    "       'month_Feb', 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar',\n",
    "       'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'weekday_Friday',\n",
    "       'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday',\n",
    "       'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday',\n",
    "       'season_fall', 'season_spring', 'season_summer', 'season_winter', 'holiday', 'holiday_school']]\n",
    "    d = pd.concat([df1,df2,df3,df4],axis=1)\n",
    "    df5 = d.filter(like='_80', axis=1)\n",
    "    X = d.drop(df5.columns,axis=1)\n",
    "    X = pd.concat([X,df_t],axis=1)\n",
    "    X = X.drop(pollutant_1,axis=1)\n",
    "    Y = d[[pollutant_1]] \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fukcija za data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X,Y):\n",
    "    X_train = X.loc[:'2020-01-02']\n",
    "    X_test = X.loc['2020-01-03':'2020-03-10']\n",
    "    y_train = Y.loc[:'2020-01-02'].values.reshape((-1, 1))\n",
    "    y_test = Y.loc['2020-01-03':'2020-03-10'].values.reshape((-1, 1))\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    X_train_t = torch.FloatTensor(X_train)\n",
    "    Y_train_t = torch.FloatTensor(y_train).reshape(-1,1) \n",
    "    X_test_t = torch.FloatTensor(X_test)\n",
    "    return X_train_t,X_test_t,Y_train_t,y_test,X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funckija model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_torch(input_size,hidden_size,hidden_size_1,hidden_size_2,hidden_size_3):\n",
    "    output_size=1\n",
    "    model_t = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_size),\n",
    "                                  torch.nn.ReLU(),\n",
    "                                  torch.nn.Linear(hidden_size, hidden_size_1),\n",
    "                                  torch.nn.ReLU(),\n",
    "                                  torch.nn.Linear(hidden_size_1, hidden_size_2),\n",
    "                                  torch.nn.ReLU(),\n",
    "                                  torch.nn.Linear(hidden_size_2, hidden_size_3),\n",
    "                                  torch.nn.ReLU(),\n",
    "                                  torch.nn.Linear(hidden_size_3, output_size)) \n",
    "    return model_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcija trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,epochs,X_tr,Y_tr):\n",
    "    error = []\n",
    "    for e in range(epochs):\n",
    "    #X_train_t = torch.FloatTensor(xtrain)  #Converting numpy array to torch tensor\n",
    "    \n",
    "        y_pred = torch_model(X_tr)\n",
    "        loss = loss_func(y_pred, Y_tr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        error.append(loss.item())\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sites i polutanti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['Nord','Sud','West','Ost','DonBosco'] \n",
    "pollutant_O3 = ['N_O3','S_O3'] \n",
    "pollutant_PM10 = ['N_PM10K','S_PM10K','W_PM10K','O_PM10K','D_PM10K'] \n",
    "pollutant_NO2 = ['N_NO2','S_NO2','W_NO2','O_NO2','D_NO2'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 4000\n",
    "# hidden_size = 300\n",
    "# hidden_size_1 = 150\n",
    "# hidden_size_2 = 100\n",
    "# hidden_size_3 = 80\n",
    "\n",
    "\n",
    "# learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funkcije "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sites(site_1,pollutant_1) svi podaci \n",
    "# data_sites_bez_traffic(site_1,pollutant_1) svi podaci bez traffic \n",
    "# data_sites_s_norm_traffic(site_1,pollutant_1,traffic_1) s normaliziranim trafficom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop for train all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for site,pollutant in zip(sites,pollutant_NO2):\n",
    "#     temp_traffic = traffic_norm(site) # normalizirani promet\n",
    "#     norm_traffic = traffic_s_norm(data,temp_traffic) #normalizirani promet\n",
    "#     X,Y = data_sites_bez_traffic(site,pollutant)\n",
    "#     X_train_t,X_test_t,Y_train_t,y_test,X_train=prep_data(X,Y)\n",
    "#     input_size = X_train.shape[1]\n",
    "#     torch_model = model_torch(input_size,hidden_size,hidden_size_1,hidden_size_2,hidden_size_3)\n",
    "#     loss_func = torch.nn.MSELoss() #mean square error as loss metric\n",
    "#     optimizer = torch.optim.Adam(torch_model.parameters(), lr=learning_rate)\n",
    "#     train_error = training(torch_model,epochs,X_train_t,Y_train_t)\n",
    "# #     plt.plot(train_error)\n",
    "# #     plt.ylabel('Loss')\n",
    "# #     plt.title('Training Loss')\n",
    "# #     plt.show()\n",
    "#     ypredict = torch_model(X_test_t)\n",
    "#     ypredict_np = ypredict.detach().numpy()\n",
    "#     print(f'{site} {pollutant}')\n",
    "#     print(f'R2_Score:', r2_score(y_test, ypredict_np))\n",
    "#     print(f'MSE:', mean_squared_error(y_test, ypredict_np, squared=True))\n",
    "    \n",
    "#     plt.plot(y_test)#_inverse)\n",
    "#     plt.plot(ypredict_np)#_inverse)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop za trening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epohe = [2000,3000,5000]\n",
    "\n",
    "hidden_sizes = [10,50,100,200,300,500,1000]\n",
    "hidden_sizes_1 = [8,40,80,150,200,350,500]\n",
    "hidden_sizes_2 = [4,30,40,100,130,200,300]\n",
    "hidden_sizes_3 = [2,15,20,50,80,100,150]\n",
    "\n",
    "learning_rates = [0.1,0.01,0.001,0.0001,0.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 2000\n",
      "Start [10, 8, 4, 2]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [10, 8, 4, 2]\n",
      "Start [50, 40, 30, 15]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [50, 40, 30, 15]\n",
      "Start [100, 80, 40, 20]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [100, 80, 40, 20]\n",
      "Start [200, 150, 100, 50]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [200, 150, 100, 50]\n",
      "Start [300, 200, 130, 80]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [300, 200, 130, 80]\n",
      "Start [500, 350, 200, 100]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [500, 350, 200, 100]\n",
      "Start [1000, 500, 300, 150]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [1000, 500, 300, 150]\n",
      "Done 2000\n",
      "Start 3000\n",
      "Start [10, 8, 4, 2]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [10, 8, 4, 2]\n",
      "Start [50, 40, 30, 15]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [50, 40, 30, 15]\n",
      "Start [100, 80, 40, 20]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [100, 80, 40, 20]\n",
      "Start [200, 150, 100, 50]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [200, 150, 100, 50]\n",
      "Start [300, 200, 130, 80]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n",
      "Done 0.001\n",
      "Start 0.0001\n",
      "Done 0.0001\n",
      "Start 1e-05\n",
      "Done 1e-05\n",
      "Done [300, 200, 130, 80]\n",
      "Start [500, 350, 200, 100]\n",
      "Start 0.1\n",
      "Done 0.1\n",
      "Start 0.01\n",
      "Done 0.01\n",
      "Start 0.001\n"
     ]
    }
   ],
   "source": [
    "dictionary = {'Site':[],'pollutant':[],'R2':[],'MSE':[],'Epoch':[],'hidden':[],'lr':[]}\n",
    "for epochs in epohe: \n",
    "    print(f'Start {epochs}')\n",
    "    for hidden_size,hidden_size_1,hidden_size_2,hidden_size_3 in zip(hidden_sizes,hidden_sizes_1,hidden_sizes_2,hidden_sizes_3):\n",
    "        hidden = []\n",
    "        hidden.extend([hidden_size,hidden_size_1,hidden_size_2,hidden_size_3])\n",
    "        print(f'Start {hidden}')\n",
    "        for lr in learning_rates:\n",
    "            print(f'Start {lr}')\n",
    "            for site,pollutant in zip(sites,pollutant_PM10):\n",
    "                temp_traffic = traffic_norm(site) # normalizirani promet\n",
    "                norm_traffic = traffic_s_norm(data,temp_traffic) #normalizirani promet\n",
    "                X,Y = data_sites_bez_traffic(site,pollutant)\n",
    "                X_train_t,X_test_t,Y_train_t,y_test,X_train=prep_data(X,Y)\n",
    "                input_size = X_train.shape[1]\n",
    "                torch_model = model_torch(input_size,hidden_size,hidden_size_1,hidden_size_2,hidden_size_3)\n",
    "                loss_func = torch.nn.MSELoss() #mean square error as loss metric\n",
    "                optimizer = torch.optim.Adam(torch_model.parameters(), lr=lr)\n",
    "                train_error = training(torch_model,epochs,X_train_t,Y_train_t)\n",
    "                ypredict = torch_model(X_test_t)\n",
    "                ypredict_np = ypredict.detach().numpy()\n",
    "                r2 = r2_score(y_test, ypredict_np)\n",
    "                mse = mean_squared_error(y_test, ypredict_np, squared=True)\n",
    "                dictionary['Site'].append(site)\n",
    "                dictionary['pollutant'].append(pollutant)\n",
    "                dictionary['R2'].append(r2)\n",
    "                dictionary['MSE'].append(mse)\n",
    "                dictionary['lr'].append(lr)\n",
    "                dictionary['Epoch'].append(epochs)\n",
    "                dictionary['hidden'].append(hidden)\n",
    "            print(f'Done {lr}')\n",
    "        print(f'Done {hidden}')\n",
    "    print(f'Done {epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_excel('test1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
