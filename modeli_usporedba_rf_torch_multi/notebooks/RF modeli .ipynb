{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (r'..\\data\\data_ready.csv')\n",
    "traffic_path = (r'..\\data\\traffic_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path,index_col=0)\n",
    "traffic = pd.read_excel(traffic_path, engine='openpyxl', sheet_name='udaljenosti', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_norm(x):\n",
    "    df=traffic.drop(x,axis=0)\n",
    "    df=df[[x]]\n",
    "    df['norm']=df[[x]]/df[[x]].max()\n",
    "    df=df.drop(x,axis=1)\n",
    "    df = df.filter(like='_80',axis=0)\n",
    "    df=df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_s_norm(data,y):\n",
    "    x = data.copy()\n",
    "    x1 = x.filter(like='_80',axis=1)\n",
    "    x1 = x1.sort_index(axis=1)\n",
    "    for i,j in zip(x1.columns,y.norm):\n",
    "        x1[i]=x1[i]*j\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# podaci svi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sites(site_1,pollutant_1):\n",
    "    df = data.copy()\n",
    "    df2 = df[[pollutant_1]]\n",
    "    df1 = df.filter(like=site_1, axis=1)\n",
    "    df3 = df[['Cloud_Cover_Mean','Temperature_Air_2m_Max_Day_Time', 'Temperature_Air_2m_Min_Night_Time','Wind_Speed_10m_Mean']]\n",
    "    df4 = df[['year', 'dayofyear', 'month_Apr', 'month_Aug', 'month_Dec',\n",
    "       'month_Feb', 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar',\n",
    "       'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'weekday_Friday',\n",
    "       'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday',\n",
    "       'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday',\n",
    "       'season_fall', 'season_spring', 'season_summer', 'season_winter', 'holiday', 'holiday_school']]\n",
    "    d = pd.concat([df1,df2,df3,df4],axis=1)\n",
    "    X = d.drop(pollutant_1,axis=1)\n",
    "    Y = d[[pollutant_1]] \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# podaci bez traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sites_bez_traffic(site_1,pollutant_1):\n",
    "    df = data.copy()\n",
    "    df2 = df[[pollutant_1]]\n",
    "    df1 = df.filter(like=site_1, axis=1)\n",
    "    df3 = df[['Cloud_Cover_Mean','Temperature_Air_2m_Max_Day_Time', 'Temperature_Air_2m_Min_Night_Time','Wind_Speed_10m_Mean']]\n",
    "    df4 = df[['year', 'dayofyear', 'month_Apr', 'month_Aug', 'month_Dec',\n",
    "       'month_Feb', 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar',\n",
    "       'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'weekday_Friday',\n",
    "       'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday',\n",
    "       'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday',\n",
    "       'season_fall', 'season_spring', 'season_summer', 'season_winter', 'holiday', 'holiday_school']]\n",
    "    d = pd.concat([df1,df2,df3,df4],axis=1)\n",
    "    df5 = d.filter(like='_80', axis=1)\n",
    "    \n",
    "    X = d.drop(df5.columns,axis=1)\n",
    "    X = d.drop(pollutant_1,axis=1)\n",
    "    Y = d[[pollutant_1]] \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# podaci s norm traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sites_s_norm_traffic(site_1,pollutant_1,traffic_1):\n",
    "    df = data.copy()\n",
    "    df_t = traffic_1.copy()\n",
    "    df_t = df_t.filter(like=site_1,axis=1)\n",
    "    df2 = df[[pollutant_1]]\n",
    "    df1 = df.filter(like=site_1, axis=1)\n",
    "    df3 = df[['Cloud_Cover_Mean','Temperature_Air_2m_Max_Day_Time', 'Temperature_Air_2m_Min_Night_Time','Wind_Speed_10m_Mean']]\n",
    "    df4 = df[['year', 'dayofyear', 'month_Apr', 'month_Aug', 'month_Dec',\n",
    "       'month_Feb', 'month_Jan', 'month_Jul', 'month_Jun', 'month_Mar',\n",
    "       'month_May', 'month_Nov', 'month_Oct', 'month_Sep', 'weekday_Friday',\n",
    "       'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday',\n",
    "       'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday',\n",
    "       'season_fall', 'season_spring', 'season_summer', 'season_winter', 'holiday', 'holiday_school']]\n",
    "    d = pd.concat([df1,df2,df3,df4],axis=1)\n",
    "    df5 = d.filter(like='_80', axis=1)\n",
    "    X = d.drop(df5.columns,axis=1)\n",
    "    X = pd.concat([X,df_t],axis=1)\n",
    "    X = X.drop(pollutant_1,axis=1)\n",
    "    Y = d[[pollutant_1]] \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X,Y):\n",
    "    X_train = X.loc[:'2020-01-02']\n",
    "    X_test = X.loc['2020-01-03':'2020-03-10']\n",
    "    y_train = Y.loc[:'2020-01-02']\n",
    "    y_test = Y.loc['2020-01-03':'2020-03-10']\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeli rf i knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'kn':KNeighborsRegressor,\n",
    "          'rf':RandomForestRegressor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['Nord','Sud','West','Ost','DonBosco'] \n",
    "pollutant_O3 = ['N_O3','S_O3'] \n",
    "pollutant_PM10 = ['N_PM10K','S_PM10K','W_PM10K','O_PM10K','D_PM10K'] \n",
    "pollutant_NO2 = ['N_NO2','S_NO2','W_NO2','O_NO2','D_NO2'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nord N_O3 \n",
      "R2_Score: 0.25267539030052666\n",
      "MSE: 262.75326926747283\n",
      "Sud S_O3 \n",
      "R2_Score: 0.5666366641708473\n",
      "MSE: 112.8602047461655\n"
     ]
    }
   ],
   "source": [
    "for site,pollutant in zip(sites,pollutant_O3): \n",
    "    X,Y = data_sites(site,pollutant)\n",
    "    X_train,X_test,Y_train,Y_test=prep_data(X,Y)\n",
    "    model = KNeighborsRegressor()\n",
    "    model.fit(X_train,Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    r2 = r2_score(Y_test, predictions)\n",
    "    mse = mean_squared_error(Y_test, predictions, squared=True)\n",
    "    print(f'{site} {pollutant} ')\n",
    "    print(f'R2_Score:', r2_score(Y_test, predictions))\n",
    "    print(f'MSE:', mean_squared_error(Y_test, predictions, squared=True))\n",
    "    \n",
    "#     figure(figsize=(12, 6), dpi=80)\n",
    "#     plt.xticks(rotation=90, ha='right')\n",
    "#     plt.plot(Y_test)#_inverse)\n",
    "#     plt.plot(predictions)#_inverse)\n",
    "#     plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nord N_O3 \n",
      "R2_Score: 0.6615830344708817\n",
      "MSE: 118.98465929565943\n",
      "Sud S_O3 \n",
      "R2_Score: 0.78233034763903\n",
      "MSE: 56.687401774502284\n"
     ]
    }
   ],
   "source": [
    "for site,pollutant in zip(sites,pollutant_O3): \n",
    "    temp_traffic = traffic_norm(site) # normalizirani promet\n",
    "    norm_traffic = traffic_s_norm(data,temp_traffic) #normalizirani promet\n",
    "    X,Y = data_sites_s_norm_traffic(site,pollutant,norm_traffic)\n",
    "    X_train,X_test,Y_train,Y_test=prep_data(X,Y)\n",
    "    model = RandomForestRegressor(random_state=1)\n",
    "    model.fit(X_train,Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    r2 = r2_score(Y_test, predictions)\n",
    "    mse = mean_squared_error(Y_test, predictions, squared=True)\n",
    "    print(f'{site} {pollutant} ')\n",
    "    print(f'R2_Score:', r2_score(Y_test, predictions))\n",
    "    print(f'MSE:', mean_squared_error(Y_test, predictions, squared=True))\n",
    "    \n",
    "#     figure(figsize=(12, 6), dpi=80)\n",
    "#     plt.xticks(rotation=90, ha='right')\n",
    "#     plt.plot(Y_test)#_inverse)\n",
    "#     plt.plot(predictions)#_inverse)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multitarget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = multi.filter(like='_80',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM10 = data.filter(like='PM10K',axis=1)\n",
    "NO = data.filter(like='NO',axis=1)\n",
    "O3 = data.filter(like='_O3',axis=1)\n",
    "NOX = data.filter(like='NOX',axis=1)\n",
    "Ox = data.filter(like='_Ox',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO2 = data.filter(like='NO2',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = multi.drop(PM10,axis=1)\n",
    "multi = multi.drop(NO,axis=1)\n",
    "multi = multi.drop(O3,axis=1)\n",
    "multi = multi.drop(Ox,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = multi.loc[:'2020-01-02']\n",
    "X_test = multi.loc['2020-01-03':'2020-03-10']\n",
    "y_train = NO2.loc[:'2020-01-02']\n",
    "y_test = NO2.loc['2020-01-03':'2020-03-10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM = pd.DataFrame(y_test,columns=NO2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions,columns=NO2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_NO2\n",
      "R2 0.5097208073011139\n",
      "mse 60.21778730697081\n",
      "N_NO2\n",
      "R2 0.6440888226873311\n",
      "mse 41.02318103932081\n",
      "O_NO2\n",
      "R2 0.43580035852599086\n",
      "mse 64.80312925898099\n",
      "S_NO2\n",
      "R2 0.5145406181175305\n",
      "mse 46.30993135763425\n",
      "W_NO2\n",
      "R2 0.68279452127843\n",
      "mse 37.43785815109094\n"
     ]
    }
   ],
   "source": [
    "for i in PM.columns:\n",
    "    r2 = r2_score(PM[i],pred[i])\n",
    "    mse = mean_squared_error(PM[i],pred[i], squared=True)\n",
    "    print(i)\n",
    "    print(f'R2 {r2}')\n",
    "    print(f'mse {mse}')\n",
    "#     plt.plot(PM[i])#_inverse)\n",
    "#     plt.plot(pred[i])#_inverse)\n",
    "#     plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multitarget bez traffic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_bez_traffic = multi.drop(traffic,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = multi_bez_traffic .loc[:'2020-01-02']\n",
    "X_test_1 = multi_bez_traffic .loc['2020-01-03':'2020-03-10']\n",
    "y_train = NO2.loc[:'2020-01-02']\n",
    "y_test = NO2.loc['2020-01-03':'2020-03-10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = sc.fit_transform(X_train_1)\n",
    "X_test_1 = sc.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = RandomForestRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train_1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_1.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_1 = pd.DataFrame(y_test,columns=NO2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions,columns=NO2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_NO2\n",
      "R2 0.479453642230824\n",
      "mse 63.935305275772485\n",
      "N_NO2\n",
      "R2 0.6469012533906251\n",
      "mse 40.69901349062813\n",
      "O_NO2\n",
      "R2 0.3367670723403098\n",
      "mse 76.17794479212412\n",
      "S_NO2\n",
      "R2 0.4757164504088498\n",
      "mse 50.013525538128576\n",
      "W_NO2\n",
      "R2 0.6878047786638679\n",
      "mse 36.84652755348445\n"
     ]
    }
   ],
   "source": [
    "for i in PM.columns:\n",
    "    r2 = r2_score(PM[i],pred[i])\n",
    "    mse = mean_squared_error(PM[i],pred[i], squared=True)\n",
    "    print(i)\n",
    "    print(f'R2 {r2}')\n",
    "    print(f'mse {mse}')\n",
    "#     plt.plot(PM[i])#_inverse)\n",
    "#     plt.plot(pred[i])#_inverse)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
