{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (r'..\\data\\data_ready.csv')\n",
    "traffic_path = (r'..\\data\\traffic_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path,index_col=0)\n",
    "traffic = pd.read_excel(traffic_path, engine='openpyxl', sheet_name='udaljenosti', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# site i polutanit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['Nord','Sud','West','Ost','DonBosco'] \n",
    "pollutant_O3 = ['N_O3','S_O3'] \n",
    "pollutant_PM10 = ['N_PM10K','S_PM10K','W_PM10K','O_PM10K','D_PM10K'] \n",
    "pollutant_NO2 = ['N_NO2','S_NO2','W_NO2','O_NO2','D_NO2'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM10 = data.filter(like='PM10K',axis=1)\n",
    "NO2 = data.filter(like='NO',axis=1)\n",
    "O3 = data.filter(like='_O3',axis=1)\n",
    "NOX = data.filter(like='NOX',axis=1)\n",
    "Ox = data.filter(like='_Ox',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(PM10,axis=1)\n",
    "test = test.drop(NO2,axis=1)\n",
    "test = test.drop(O3,axis=1)\n",
    "test = test.drop(Ox,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = test.loc[:'2020-01-02']\n",
    "X_test = test.loc['2020-01-03':'2020-03-10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = PM10.loc[:'2020-01-02']\n",
    "y_test = PM10.loc['2020-01-03':'2020-03-10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.FloatTensor(X_train)\n",
    "Y_train_t = torch.FloatTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_t = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=91, out_features=1000, bias=True)\n",
      "  (1): Softmax(dim=1)\n",
      "  (2): Linear(in_features=1000, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define network dimensions\n",
    "input_size = X_train.shape[1]\n",
    "# Layer size\n",
    "hidden_size = 1000 # Number of hidden nodes\n",
    "output_size = 1 # Number of output nodes for prediction\n",
    "\n",
    "# Build mdel\n",
    "torch_model = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_size),\n",
    "                                  torch.nn.Softmax(dim=1),\n",
    "                                  torch.nn.Linear(hidden_size, output_size))    \n",
    "print(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss() #mean square error as loss metric\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "epochs = 2000\n",
    "\n",
    "#Y_train_t = torch.FloatTensor(y_train).reshape(-1,1) #Converting numpy array to torch tensor\n",
    "\n",
    "for e in range(epochs):\n",
    "    #X_train_t = torch.FloatTensor(xtrain)  #Converting numpy array to torch tensor\n",
    "    \n",
    "    y_pred = torch_model(X_train_t)\n",
    "    loss = loss_func(y_pred, Y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_error.append(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredict = torch_model(X_test_t)\n",
    "# Descale\n",
    "ypredict_np = ypredict.detach().numpy()\n",
    "#ypredict_inverse = scaler_y.inverse_transform(ypredict_np)\n",
    "#ytest_inverse = scaler_y.inverse_transform(ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68, 91])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([732, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ost_8010_208', 'DonBosco_8020_110', 'DonBosco_8020_119',\n",
       "       'DonBosco_8020_122', 'DonBosco_8053_111', 'Nord_8010_205',\n",
       "       'Ost_8010_209', 'Ost_8010_213', 'Ost_8010_214', 'Nord_8020_102',\n",
       "       'West_8020_103', 'Sud_8020_107', 'Sud_8041_218', 'Ost_8041_221',\n",
       "       'Nord_8045_203', 'Nord_8051_101', 'year', 'dayofyear', 'month_Apr',\n",
       "       'month_Aug', 'month_Dec', 'month_Feb', 'month_Jan', 'month_Jul',\n",
       "       'month_Jun', 'month_Mar', 'month_May', 'month_Nov', 'month_Oct',\n",
       "       'month_Sep', 'weekday_Friday', 'weekday_Monday', 'weekday_Saturday',\n",
       "       'weekday_Sunday', 'weekday_Thursday', 'weekday_Tuesday',\n",
       "       'weekday_Wednesday', 'season_fall', 'season_spring', 'season_summer',\n",
       "       'season_winter', 'holiday', 'holiday_school', 'DonBosco_RH',\n",
       "       'DonBosco_Temp', 'Nord_Precip', 'Nord_Pressure', 'Nord_RH', 'Nord_Temp',\n",
       "       'Nord_Winddirection', 'Nord_Windspeed', 'Sud_RH', 'Sud_Temp',\n",
       "       'Sud_Winddirection', 'Sud_Windspeed', 'West_RH', 'West_Temp',\n",
       "       'West_Winddirection', 'West_Windspeed', 'Ost_Pressure', 'Ost_RH',\n",
       "       'Ost_Temp', 'Ost_Winddirection', 'Ost_Windspeed', 'Cloud_Cover_Mean',\n",
       "       'Temperature_Air_2m_Max_Day_Time', 'Temperature_Air_2m_Min_Night_Time',\n",
       "       'Wind_Speed_10m_Mean', 'Nord_Radiation', 'Nord_peek_wind_speed',\n",
       "       'Ost_peek_wind_speed', 'Sud_peek_wind_speed', 'West_peek_wind_speed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM = pd.DataFrame(y_test,columns=PM10.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions,columns=PM10.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_PM10K\n",
      "R2 0.5284211313609952\n",
      "mse 97.44071122519125\n",
      "N_PM10K\n",
      "R2 0.6143224645170202\n",
      "mse 67.83299521837546\n",
      "O_PM10K\n",
      "R2 0.39962243133290676\n",
      "mse 185.3513588978976\n",
      "S_PM10K\n",
      "R2 0.6184793560686668\n",
      "mse 93.50034434364832\n",
      "W_PM10K\n",
      "R2 0.6417880156264437\n",
      "mse 68.29717438759148\n"
     ]
    }
   ],
   "source": [
    "for i in PM.columns:\n",
    "    r2 = r2_score(PM[i],pred[i])\n",
    "    mse = mean_squared_error(PM[i],pred[i], squared=True)\n",
    "    print(i)\n",
    "    print(f'R2 {r2}')\n",
    "    print(f'mse {mse}')\n",
    "#     plt.plot(PM[i])#_inverse)\n",
    "#     plt.plot(pred[i])#_inverse)\n",
    "#     plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
