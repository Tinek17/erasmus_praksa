{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eastern-editing",
   "metadata": {},
   "source": [
    "# Working with AgERA5 dataset\n",
    "\n",
    "In this notebook we will:\n",
    "- Download several parameters from AgERA5 dataset for period 2010 - 2014 \n",
    "- Select one point representing city of Graz\n",
    "- Save the result in monthly netCDF file\n",
    "\n",
    "Besides imported libraries, to work with this notebook, please make sure that you have **dask** and **netcdf4** python libraries installed. They are used internally by **xarray** to work with netCDF files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-hazard",
   "metadata": {},
   "source": [
    "Before starting with the notebook, make sure you have an account on [Climate Data Store](https://cds.climate.copernicus.eu/cdsapp#!/home) and follow instructions on [How to install CDSAPI key](https://cds.climate.copernicus.eu/api-how-to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protective-means",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade metpy\n",
    "# pip install cdsapi\n",
    "# conda install -c conda-forge xarray dask netCDF4 bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "later-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import cdsapi\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-static",
   "metadata": {},
   "source": [
    "First function will download one month of data in netcdf daily files which will come zipped.  \n",
    "It takes as arguments: path to directory where you want to save the data, month, year, variable and statistic that is computed (minimum, maximum, mean etc) over the 24 hr period.  \n",
    "\n",
    "You can find which parameters have which statistics computed in this the web download application for this dataset:  \n",
    "https://cds.climate.copernicus.eu/terms#!/dataset/sis-agrometeorological-indicators?tab=form  \n",
    "On this page you can select parameters and see the example api request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "alternate-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_a_month(path, year, month, variable, statistic):\n",
    "    filename = path + year + '_' + month + '.zip'\n",
    "    c.retrieve(\n",
    "    'sis-agrometeorological-indicators',\n",
    "    {\n",
    "        'format': 'zip',\n",
    "        'variable': variable,\n",
    "        'statistic': statistic,\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'day': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "            '13', '14', '15',\n",
    "            '16', '17', '18',\n",
    "            '19', '20', '21',\n",
    "            '22', '23', '24',\n",
    "            '25', \n",
    "            '26', '27',\n",
    "            '28', '29', '30',\n",
    "            '31',\n",
    "        ],\n",
    "    },\n",
    "    filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-adoption",
   "metadata": {},
   "source": [
    "This function will unzip the file in the directory that is named by the year.  This was for my convinience, because I had other netcdf files in the parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "different-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(path,year,month):\n",
    "    filename = path + year + '_' + month + '.zip'\n",
    "    new_dir = path + year\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-christmas",
   "metadata": {},
   "source": [
    "This function deletes all the files in the 'year' directory as well as zip file (as the next downloaded file will have the same name, it does not contain variable name).  \n",
    "This was just for my convenience again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "first-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_month_files(path,year,month):\n",
    "    path_to_year = path + year\n",
    "    for f in Path(path_to_year).glob('*.nc'):\n",
    "        try:\n",
    "            f.unlink()\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "    zip_to_delete = path + year + '_' + month + '.zip'\n",
    "    os.remove(zip_to_delete)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-labor",
   "metadata": {},
   "source": [
    "Here we define the years and months we want to download as well as path to where we want to save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "attempted-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(i) for i in range(2010, 2022)]\n",
    "months = [\n",
    "            '01', \n",
    "    '02', \n",
    "    '03',\n",
    "    '04', '05', '06',\n",
    "    '07', '08', '09',\n",
    "    '10', \n",
    "    '11', \n",
    "    '12',\n",
    "    ]\n",
    "\n",
    "path = '../../data/'\n",
    "\n",
    "\n",
    "# parameter = [('cloud_cover','24_hour_mean'),\n",
    "#              ('2m_temperature','day_time_maximum'),\n",
    "#              ('2m_temperature','night_time_minimum'),\n",
    "#              ('10m_wind_speed','24_hour_mean'),\n",
    "             \n",
    "#              ('liquid_precipitation_duration_fraction',''),\n",
    "#              ('solar_radiation_flux',''),             \n",
    "#              ('precipitation_flux',''),\n",
    "#              ('solid_precipitation_duration_fraction', ''),\n",
    "#              ('2m_dewpoint_temperature','24_hour_mean'),\n",
    "#              ('vapour_pressure', '24_hour_mean'),\n",
    "\n",
    "# ]\n",
    "\n",
    "parameter = [\n",
    "             ('2m_dewpoint_temperature','24_hour_mean'),\n",
    "             ('vapour_pressure', '24_hour_mean'),\n",
    "#              (2m_relative_humidity)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-belief",
   "metadata": {},
   "source": [
    "We make an output directory for final data to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "painted-triumph",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graz_dir = path + 'graz_data/'\n",
    "Path(graz_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-disclaimer",
   "metadata": {},
   "source": [
    "We define parameters and computed statistics we want.  \n",
    "**Note** that not all combinations of parameters and statistics are allowed. You can see which parameter has what calculated in the CDS web download applicaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-commission",
   "metadata": {},
   "source": [
    "And finally we run the whole workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-street",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    new_dir = path + year\n",
    "    Path(new_dir).mkdir(parents=True, exist_ok=True)    \n",
    "    for variable, statistic in parameter:\n",
    "        for month in months:\n",
    "            retrieve_a_month(path,year,month,variable, statistic)\n",
    "            unzip_file(path,year,month)\n",
    "            nc_directory = path + year\n",
    "            #open the dataset\n",
    "            data = xr.open_mfdataset(nc_directory + '/*.nc')\n",
    "            #filter the point representing Graz\n",
    "            graz_data = data.sel(lat = 47.0, lon = 15.4, method = 'nearest')\n",
    "            #make a filename\n",
    "            nc_name = graz_dir + 'graz_' + variable + '_' + statistic + '_' + year + '_' + month + '.nc'\n",
    "            #save as netcdf\n",
    "            graz_data.to_netcdf(nc_name)\n",
    "            #delete all the data because it is kind of a lot if we keep all\n",
    "            delete_month_files(path,year,month)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-tobago",
   "metadata": {},
   "source": [
    "Now we can open the new small netcdf files using xarray again. From there we can convert to pandas dataframe as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-friendship",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# graz_dir = '../../output_intermediate/95_graz_data'\n",
    "graz_dir = '../../data/graz_data'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for variable, statistic in parameter:\n",
    "    tmp2 = pd.DataFrame()\n",
    "#     for year in range(2010, 2022):\n",
    "    for year in years:\n",
    "        tmp1 = pd.DataFrame()\n",
    "        for month in months:\n",
    "            path = os.path.join(graz_dir, \n",
    "                                'graz_' + variable + '_' + statistic + f'_{year}_' + month + '.nc')    \n",
    "            try:\n",
    "                tmp = xr.open_mfdataset(path).to_dataframe().drop(['lon', 'lat'], axis=1).drop_duplicates()\n",
    "                tmp1 = pd.concat([tmp1, tmp], axis=0)\n",
    "            except:\n",
    "                print(f'failed: {path}')\n",
    "\n",
    "        tmp2 = pd.concat([tmp2, tmp1], axis=0)\n",
    "        print(f'Done year: {year}')\n",
    "\n",
    "    print(f'Done: {variable}')\n",
    "    df = df.join(tmp2, how='outer')\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-sleep",
   "metadata": {},
   "source": [
    "df.to_csv('AgERA5_4params_graz.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
